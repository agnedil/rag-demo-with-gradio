
# Advanced RAG System

This repository contains the code for a Gradio web app that demoes a Retrieval-Augmented Generation (RAG) system. This app is designed to allow users to load multiple documents of their choice into a vector database, submit queries, and receive answers generated by a sophisticated RAG system that leverages the latest advancements in natural language processing and information retrieval technologies.

## Features

#### 1. Dynamic Processing
- Users can load multiple source documents of their choice into a vector store in real-time.
- Users can submit queries which are processed in real-time for enhanced retrieval and generation.

#### 2. PDF Integration
- The system allows for the loading of multiple PDF documents into a vector store, enabling the RAG system to retrieve information from a vast corpus.

#### 3. Advanced RAG System
Integrates various components, including:
- **UI**: Allows users to input URLs for documents and then input user queries; displays the LLM response.
- **Document Loader**: Loads documents from URLs.
- **Text Splitter**: Chunks loaded documents.
- **Vector Store**: Embeds text chunks and adds them to a FAISS vector store; embeds user queries.
- **Retrievers**: Uses an ensemble of BM25 and FAISS retrievers, along with a Cohere reranker, to retrieve relevant document chunks based on user queries.
- **Language Model**: Utilizes a Llama 2 large language model for generating responses based on the user query and retrieved context.

#### 4. PDF and Query Error Handling
- Validates PDF URLs and queries to ensure that they are not empty and that they are valid.
- Displays error messages for empty queries or issues with the RAG system.

#### 5. Refresh Mechanism
- Instructs users to refresh the page to clear / reset the RAG system.

## Installation

To run this application, you need to have Python and Gradio installed. Follow these steps:

1. Clone this repository to your local machine.
2. Create and activate a virtual environment of your choice (venv, conda, etc.).
3. Install dependencies from the requirements.txt file by running `pip install -r requirements.txt`.
4. Set up environment variables REPLICATE_API_TOKEN (for a Llama 2 model hosted on replicate.com) and COHERE_API_KEY (for embeddings and reranking service on cohere.com)
4. Start the Gradio app by running `python app.py`.

## Licence
MIT license